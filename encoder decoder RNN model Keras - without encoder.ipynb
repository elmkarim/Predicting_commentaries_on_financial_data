{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unilever decoder RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "<img src=\"./images/architecture2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Imports -----\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch import optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "# import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a text file for test purpouses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='ansi')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that splits a loaded document into sentences\n",
    "def to_lines(doc):\n",
    "    exclude = set(string.punctuation)\n",
    "    doc2 = ''.join(ch for ch in doc if ch not in exclude)\n",
    "    lines = doc2.strip().split('\\n')\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "filename = 'sample_text.txt'\n",
    "doc = load_doc(filename)\n",
    "lines = to_lines(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for the decoder\n",
    "Get commentaries and dictionary from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataframes from pickle file (saved previously)\n",
    "from helper_save_load import load_from_pickle\n",
    "import pandas\n",
    "dfc, vocab, word_to_ix, ix_to_word = load_from_pickle(\"commentaries.pickle\")\n",
    "# display(dfc.head(2))\n",
    "# print('index of word lcl:', word_to_ix['lcl'])\n",
    "# print('word at index 0:', ix_to_word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['Comment_w'].replace('[NOC]', '[SOS] [EOS]', inplace=True)   #replace NoComment with StartOfSentence + EndOfSentence\n",
    "commentaries = dfc['Comment_w']\n",
    "commentaries[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commentaries = lines\n",
    "# commentaries[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing words (RNN2 inputs and outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tokenizer for commentaries\n",
    "tokenizer = create_tokenizer(commentaries)\n",
    "# tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (vocab_size): 678\n",
      "Max length of commentary (com_length): 127\n",
      "Number of commentaries : 1093\n"
     ]
    }
   ],
   "source": [
    "#Calculate vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "#Calculate maximum length of commentaries\n",
    "com_length = max_length(commentaries)\n",
    "\n",
    "print('Vocabulary size (vocab_size):', vocab_size)\n",
    "print('Max length of commentary (com_length):', com_length)\n",
    "print('Number of commentaries :', len(commentaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter only non empty commentaries\n",
    "commentaries = [c for c in commentaries if c != '[SOS] [EOS]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX=\n",
      " [[  1  18  19 ...   0   0   0]\n",
      " [  1  18  19 ...   0   0   0]\n",
      " [  1 130  68 ...   0   0   0]\n",
      " ...\n",
      " [  1   4  38 ...   0   0   0]\n",
      " [  1   3  71 ...   0   0   0]\n",
      " [  1   3  71 ...   0   0   0]]\n",
      "\n",
      "trainY=\n",
      " [[ 18  19 388 ...   0   0   0]\n",
      " [ 18  19   8 ...   0   0   0]\n",
      " [130  68   2 ...   0   0   0]\n",
      " ...\n",
      " [  4  38  22 ...   0   0   0]\n",
      " [  3  71   6 ...   0   0   0]\n",
      " [  3  71   6 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n",
    "\n",
    "#Tokenizing all comments\n",
    "\n",
    "\n",
    "\n",
    "trainX = encode_sequences(tokenizer, com_length, commentaries)\n",
    "print('trainX=\\n', trainX)\n",
    "\n",
    "#Shifting tokenized words by 1 to predict next word in RNN2\n",
    "trainY = np.zeros((len(commentaries), com_length), dtype='int')\n",
    "trainY[:,0:com_length-2] = trainX[:,1:com_length-1]\n",
    "# trainY = trainX\n",
    "print('\\ntrainY=\\n', trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding RNN2 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y\n",
    "\n",
    "trainY = encode_output(trainY, vocab_size)\n",
    "# trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encode inputs in trainX_oh \n",
    "# trainX_oh = encode_output(trainX, vocab_size)\n",
    "# trainX_oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decoder (RNN2)\n",
    "\n",
    "Receives the variance vector that is concatenated with the embedding vector of the word, then is trained to predict the next word using the current word from the commentary of month i related to brand k. \n",
    "\n",
    "**It makes senses also to classify the commentaries in classes, such as: over delivery, driven by territory, orders phased, ...**\n",
    "\n",
    "<img src=\"./images/decoder-arch.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder_input_data = (comment_num, variance pos, variance value)  => dimension (comment len, variance vector len, 1)\n",
    "\n",
    "decoder_input_data = (comment num, word pos, word one-hot encoded vector) => (comments number, comment len, vocab_size )\n",
    "\n",
    "decoder_target_data = (comment num, word pos, word one-hot encoded vector) - words are shifted of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN2** :\n",
    "- **samples**: number of comments: `num_comments` \n",
    "- **time steps**: max length of a commentary: `com_length`\n",
    "- **Features**: token of each time step: `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without encoder +embedding (without variance inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: embed_size = 100\n",
      "Size of LSTM: hidden_size = 300\n",
      "Commentaries vocabulary length: src_vocab = 678\n",
      "Commentaries length (output): src_timesteps = 127\n",
      "Number of commentaries: num_comments = 275\n"
     ]
    }
   ],
   "source": [
    "#Embedding size\n",
    "embed_size = 100\n",
    "# Preparing parameters\n",
    "hidden_size = 300\n",
    "# Number of words in vocabulary\n",
    "src_vocab = vocab_size\n",
    "tar_vocab = src_vocab\n",
    "# Max length of input/ouput sentence\n",
    "src_timesteps = com_length #max(len(line.split()) for line in dfc['Comment_w'])\n",
    "tar_timesteps = src_timesteps\n",
    "# Length of variance vector\n",
    "# varv_length = len(empty_df.columns)\n",
    "# Number of commentaries\n",
    "num_comments = len(commentaries)\n",
    "\n",
    "#Overview of the parameters calculated from dataset\n",
    "print('Embedding size: embed_size =', embed_size)\n",
    "print('Size of LSTM: hidden_size =', hidden_size)\n",
    "print('Commentaries vocabulary length: src_vocab =', src_vocab)\n",
    "print('Commentaries length (output): src_timesteps =', src_timesteps)\n",
    "# print('Variance vector length: varv_length =', varv_length)\n",
    "print('Number of commentaries: num_comments =', num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 100)         67800     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 300)         481200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 678)         204078    \n",
      "=================================================================\n",
      "Total params: 753,078\n",
      "Trainable params: 753,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##################  Second version without variance vector, only training on commentaries with RNN2 #################\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))    #src_timesteps #we feed the decoder with tokenized word\n",
    "\n",
    "word_Embedding = Embedding(src_vocab, embed_size,  mask_zero=True)  #input_length=src_timesteps,\n",
    "embded_out = word_Embedding(decoder_inputs)\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True)      #, return_sequences=True, return_state=True)\n",
    "decoder_outputs = decoder_lstm(embded_out)  #.reshape(-1,embed_size)     #(decoder_inputs)\n",
    "\n",
    "decoder_dense = Dense(src_vocab, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model(decoder_inputs, decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')      #rmsprop\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3323\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.33229, saving model to unilever_WVOH.h5\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 12s 43ms/step - loss: 0.3299\n",
      "\n",
      "Epoch 00002: loss improved from 0.33229 to 0.32993, saving model to unilever_WVOH.h5\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 12s 44ms/step - loss: 0.3277\n",
      "\n",
      "Epoch 00003: loss improved from 0.32993 to 0.32774, saving model to unilever_WVOH.h5\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 12s 43ms/step - loss: 0.3285\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.32774\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3246\n",
      "\n",
      "Epoch 00005: loss improved from 0.32774 to 0.32460, saving model to unilever_WVOH.h5\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 12s 43ms/step - loss: 0.3248\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.32460\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 12s 43ms/step - loss: 0.3280\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.32460\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3278\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.32460\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3261\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.32460\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 12s 42ms/step - loss: 0.3285\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.32460\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 11s 42ms/step - loss: 0.3253\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.32460\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3267\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.32460\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3272\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.32460\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 11s 41ms/step - loss: 0.3242\n",
      "\n",
      "Epoch 00014: loss improved from 0.32460 to 0.32423, saving model to unilever_WVOH.h5\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 12s 43ms/step - loss: 0.3248\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.32423\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 11s 41ms/step - loss: 0.3261\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.32423\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 11s 41ms/step - loss: 0.3250\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.32423\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 12s 42ms/step - loss: 0.3228\n",
      "\n",
      "Epoch 00018: loss improved from 0.32423 to 0.32278, saving model to unilever_WVOH.h5\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 12s 43ms/step - loss: 0.3255\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.32278\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3231\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.32278\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3269\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.32278\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3279\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.32278\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3224\n",
      "\n",
      "Epoch 00023: loss improved from 0.32278 to 0.32244, saving model to unilever_WVOH.h5\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3231\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.32244\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3229\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.32244\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3218\n",
      "\n",
      "Epoch 00026: loss improved from 0.32244 to 0.32176, saving model to unilever_WVOH.h5\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 11s 41ms/step - loss: 0.3205\n",
      "\n",
      "Epoch 00027: loss improved from 0.32176 to 0.32046, saving model to unilever_WVOH.h5\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 11s 41ms/step - loss: 0.3217\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.32046\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3236\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.32046\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3240\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.32046\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3215\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.32046\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3241\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.32046\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3211\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.32046\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3211\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.32046\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3230\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.32046\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3186\n",
      "\n",
      "Epoch 00036: loss improved from 0.32046 to 0.31863, saving model to unilever_WVOH.h5\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 11s 42ms/step - loss: 0.3220\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.31863\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3195\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.31863\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3231\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.31863\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3194\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.31863\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3204\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.31863\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3242\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.31863\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3264\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.31863\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3196\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.31863\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3166\n",
      "\n",
      "Epoch 00045: loss improved from 0.31863 to 0.31660, saving model to unilever_WVOH.h5\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 11s 41ms/step - loss: 0.3200\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.31660\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3204\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.31660\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3177\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.31660\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3193\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.31660\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3206\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.31660\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3180\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.31660\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3202\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.31660\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3185\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.31660\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3199\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.31660\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3170\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.31660\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3158\n",
      "\n",
      "Epoch 00056: loss improved from 0.31660 to 0.31578, saving model to unilever_WVOH.h5\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 11s 41ms/step - loss: 0.3218\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.31578\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3186\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.31578\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3155\n",
      "\n",
      "Epoch 00059: loss improved from 0.31578 to 0.31549, saving model to unilever_WVOH.h5\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 11s 41ms/step - loss: 0.3158\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.31549\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3180\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.31549\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3173\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.31549\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3183\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.31549\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 10s 37ms/step - loss: 0.3213\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.31549\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 10s 37ms/step - loss: 0.3215\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.31549\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 10s 37ms/step - loss: 0.3190\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.31549\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3206\n",
      "\n",
      "Epoch 00067: loss did not improve from 0.31549\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3145\n",
      "\n",
      "Epoch 00068: loss improved from 0.31549 to 0.31447, saving model to unilever_WVOH.h5\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3157\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.31447\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3163\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.31447\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 10s 37ms/step - loss: 0.3200\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.31447\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3125\n",
      "\n",
      "Epoch 00072: loss improved from 0.31447 to 0.31255, saving model to unilever_WVOH.h5\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 11s 40ms/step - loss: 0.3155\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.31255\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3147\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.31255\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3191\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.31255\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3171\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.31255\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3140\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.31255\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3153\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.31255\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3142\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.31255\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3147\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.31255\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3134\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.31255\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3149\n",
      "\n",
      "Epoch 00082: loss did not improve from 0.31255\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3169\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.31255\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3129\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.31255\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3256\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.31255\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 11s 38ms/step - loss: 0.3195\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.31255\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 10s 37ms/step - loss: 0.3195\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.31255\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3132\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.31255\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3217\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.31255\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3159\n",
      "\n",
      "Epoch 00090: loss did not improve from 0.31255\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3212\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.31255\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 11s 39ms/step - loss: 0.3175\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.31255\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3180\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.31255\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3154\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.31255\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3166\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.31255\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3131\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.31255\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3140\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.31255\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3137\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.31255\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3158\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.31255\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 10s 38ms/step - loss: 0.3163\n",
      "\n",
      "Epoch 00100: loss did not improve from 0.31255\n"
     ]
    }
   ],
   "source": [
    "################## Training model without variance #################################\n",
    "batch_size = 20\n",
    "epochs = 100\n",
    "\n",
    "filename = 'unilever_WVOH.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, callbacks=[checkpoint], verbose=1)\n",
    "#validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "# test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'b')\n",
    "# plt.plot(epoch_count, test_loss, 'b')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Sampling model without encoder + Embedding #################\n",
    "decoder_outputs = word_Embedding(decoder_inputs)\n",
    "decoder_outputs = decoder_lstm(decoder_outputs)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(decoder_inputs, decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_word_index = dict((i+1, word) for i, word in enumerate(tokenizer.word_index))\n",
    "reverse_input_word_index[0] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Sampling with model without encoder + Embedding ########\n",
    "import sys\n",
    "\n",
    "for i in range(1,50):\n",
    "    c = random.randint(0,len(commentaries)-1)\n",
    "    comment = commentaries[c].split()\n",
    "    if comment[1] == '[EOS]': continue\n",
    "\n",
    "    print('\\nc=',c)\n",
    "    print('Original comment: ', commentaries[c])    \n",
    "\n",
    "    # Generate empty target sequence.\n",
    "    target_seq = np.zeros((1, 1))  \n",
    "    # Populate the first character of target sequence with the start character.\n",
    "#     target_seq[0, 0] = tokenizer.word_index['[sos]']       \n",
    "\n",
    "    seed = comment[0].lower()\n",
    "    target_seq[0, 0] = tokenizer.word_index[seed]\n",
    "    print('seed word:', seed)\n",
    "    sys.stdout.write(seed)\n",
    "    sys.stdout.write('-----')\n",
    "    decoded_sentence = []\n",
    "    decoded_sentence.append (seed)\n",
    "\n",
    "#     target_seq = trainXr[c:c+1]\n",
    "#     print('target_seq =', target_seq)\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens = decoder_model.predict(target_seq)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        sampled_word = reverse_input_word_index[sampled_token_index]\n",
    "        decoded_sentence.append (sampled_word)\n",
    "        \n",
    "#         print(reverse_input_word_index[target_seq[0, 0]],' -->',sampled_word)\n",
    "        \n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (len(decoded_sentence) > src_timesteps):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        if i<len(comment):\n",
    "            target_seq[0, 0] = tokenizer.word_index[comment[i].lower()]\n",
    "            i = i + 1\n",
    "        else:\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "            \n",
    "#         target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        \n",
    "    print('Result =', ' '.join(decoded_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embedding): Embedding(1, 300)\n",
      "  (gru): GRU(300, 300)\n",
      "  (out): Linear(in_features=300, out_features=1, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder = DecoderRNN(300, 1)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define components sizes\n",
    "CONTEXT_SIZE_1 = 300\n",
    "CONTEXT_SIZE_2 = 300\n",
    "EMBEDDING_DIM = 30\n",
    "\n",
    "\n",
    "encoder = EncoderRNN(VAR_MONTH_DATA_SIZE, CONTEXT_SIZE_1)\n",
    "decoder = DecoderRNN(CONTEXT_SIZE_2, 1)\n",
    "\n",
    "learning_rate=0.01\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteration here\n",
    "encoder_hidden = encoder.initHidden()\n",
    "encoder_optimizer.zero_grad()\n",
    "decoder_optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training, you can re-run this function as much time as needed to train more\n",
    "for epoch in range(60):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    print('epoch %d : Total loss=%.3f' % (epoch, total_loss))\n",
    "#print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) #Embedding matrix: each line is the embedding of one word\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128) #Parameter matrix embedding and hidden layer\n",
    "        self.linear2 = nn.Linear(128, vocab_size)  #Parameter matrix between hidden layer and output\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))  #get embedding from Embedding matrix\n",
    "        out = F.relu(self.linear1(embeds))  #\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)   #before 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training, you can re-run this function as much time as needed to train more\n",
    "for epoch in range(60):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    print('epoch %d : Total loss=%.3f' % (epoch, total_loss))\n",
    "#print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "          max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting results\n",
    "----------------\n",
    "\n",
    "Plotting is done with matplotlib, using the array of loss values\n",
    "``plot_losses`` saved while training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a paragraph with in between and then there are cases ... where the number ranges from 1-100. and there are many other lines in the txt files with such tags '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line='this is a paragraph with<[1> in between</[1> and then there are cases ... where the<[99> number ranges from 1-100</[99>. and there are many other lines in the txt files with<[3> such tags </[3>'\n",
    "import re\n",
    "line = re.sub(r\"</?\\[\\d+>\", \"\", line)\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "comment = 'baselines driven by improving pos l4 +3%'\n",
    "aa = r\"[0-9]+(\\.[0-9]+)?\\%\"\n",
    "comment = re.sub(aa, \"[%]\", comment)\n",
    "comment = re.sub(r\"\\-\\$[0-9].[0-9][0-9]M\\b\", \"[-]\", comment)\n",
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/(^|\\W)$[0-9]+(\\.[0-9][0-9])?\\b/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated version of Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, None, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 200), (None, 176800      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 200),  184800      input_6[0][0]                    \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 30)     6030        lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 367,630\n",
      "Trainable params: 367,630\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "num_encoder_tokens = 20\n",
    "latent_dim = 200\n",
    "encoder_inputs = 1\n",
    "\n",
    "num_decoder_tokens = 30\n",
    "decoder_outputs = 150\n",
    "\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 200), (None, 240800      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 200),  200800      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 50)     10050       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 451,650\n",
      "Trainable params: 451,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
