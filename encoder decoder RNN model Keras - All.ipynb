{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unilever encoder decoder RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "<img src=\"./images/architecture2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ---- Imports -----\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data for the encoder\n",
    "Get the data of Brand/territory variance matrix by month.\n",
    "Not all brands are shipped to all territories. Therefore, filtering on a specific brand may return only some territories and not all of them. That is why it is important to get all territories and associate a zero to the ones who are missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataframes from pickle file (saved previously)\n",
    "from helper_save_load import load_from_pickle\n",
    "df_a, df_f, df_v = load_from_pickle(\"dataframes_Dollars.pickle\")\n",
    "del df_a, df_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping territories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "territories = [territory for territory, values in df_v.groupby(['Territory']).groups.items()]\n",
    "print(territories)\n",
    "print(len(territories),' territories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame(0.0, index=[0], columns=territories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving variance vector from brand and month\n",
    "This function gets from the A/F dataset the variance by territory for a given month and brand. Multibrands are not supported, only `Brand_1` is considered in this study. The order of territories is the same as the `territories` vector. In case no data is available, a zero vector is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.027350e-03,  1.380900e-03,  0.000000e+00,  0.000000e+00,\n",
       "       -9.378000e-05,  1.371011e-02, -6.985500e-04, -1.274860e-03,\n",
       "        0.000000e+00,  0.000000e+00,  2.840290e-03,  1.669580e-03,\n",
       "       -5.781450e-03,  3.096440e-03, -1.241803e-02,  0.000000e+00,\n",
       "        1.315100e-04, -8.686940e-03,  0.000000e+00, -5.194400e-04,\n",
       "        2.118400e-04,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  5.971960e-03,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00, -2.078000e-04])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return pivot table for the required month in Millions of $\n",
    "def get_pivot_month_Territory_by_brand(month, brand, flatten=1):\n",
    "    #Group by Territory and Brand\n",
    "    df_group_Br_Tr = df_v[df_v['Brand'] == brand].groupby(['Brand', 'Territory']).sum()\n",
    "    result = pd.pivot_table(df_group_Br_Tr, values=[month], index=['Brand'], \n",
    "                            columns=['Territory'], aggfunc=np.sum, fill_value=0) / 1e6\n",
    "    result.columns = result.columns.droplevel()  #drop month level as there is only one month\n",
    "    if len(result.index)>0:   #if no data is available, return a zero vector\n",
    "    #Align with empty_df that includes all territories\n",
    "        result = empty_df.append(result, sort=True).fillna(0)      \n",
    "        result.drop(0, inplace=True)  #drop line 0 of empty_df\n",
    "    else:\n",
    "        result = empty_df \n",
    "    if (flatten==1): result = result.values.flatten()\n",
    "    return (result)  \n",
    "\n",
    "\n",
    "get_pivot_month_Territory_by_brand('Jan_2018', '05-AXE SA Brand', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for the decoder\n",
    "Get commentaries and dictionary from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataframes from pickle file (saved previously)\n",
    "from helper_save_load import load_from_pickle\n",
    "dfc, vocab, word_to_ix, ix_to_word = load_from_pickle(\"commentaries.pickle\")\n",
    "display(dfc.head(2))\n",
    "print('index of word lcl:', word_to_ix['lcl'])\n",
    "print('word at index 0:', ix_to_word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print('Comparing results columns and territories vector ...')\n",
    "# for index, row in dfc.iterrows():\n",
    "#     vector = get_pivot_month_Territory_by_brand(row['Month_f'], row['Brand_1'], 0)\n",
    "# #     display(vector)\n",
    "#     diff = [i for i, j in zip(vector.columns.tolist(), territories) if i != j]\n",
    "#     if len(diff) != 0: \n",
    "#         print('Differences found !!!!!')\n",
    "#         print(row['Month_f'], '**', row['Comment_w'], '**', row['Brand_1'])        \n",
    "#         print(diff)\n",
    "# print('All columns were parsed, the differences should be shown by the loop if there are any!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['Comment_w'].replace('[NOC]', '[SOS] [EOS]', inplace=True)   #replace NoComment with StartOfSentence + EndOfSentence\n",
    "commentaries = dfc['Comment_w']\n",
    "commentaries[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing words (RNN2 inputs and outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tokenizer for commentaries\n",
    "tokenizer = create_tokenizer(commentaries)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (vocab_size): 678\n",
      "Max length of commentary (com_length): 127\n",
      "Number of commentaries : 1093\n"
     ]
    }
   ],
   "source": [
    "#Calculate vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "#Calculate maximum length of commentaries\n",
    "com_length = max_length(commentaries)\n",
    "\n",
    "print('Vocabulary size (vocab_size):', vocab_size)\n",
    "print('Max length of commentary (com_length):', com_length)\n",
    "print('Number of commentaries :', len(commentaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter only non empty commentaries\n",
    "commentaries = [c for c in commentaries if c != '[SOS] [EOS]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX=\n",
      " [[  1  18  19 ...   0   0   0]\n",
      " [  1  18  19 ...   0   0   0]\n",
      " [  1 130  68 ...   0   0   0]\n",
      " ...\n",
      " [  1   4  38 ...   0   0   0]\n",
      " [  1   3  71 ...   0   0   0]\n",
      " [  1   3  71 ...   0   0   0]]\n",
      "\n",
      "trainY=\n",
      " [[ 18  19 388 ...   0   0   0]\n",
      " [ 18  19   8 ...   0   0   0]\n",
      " [130  68   2 ...   0   0   0]\n",
      " ...\n",
      " [  4  38  22 ...   0   0   0]\n",
      " [  3  71   6 ...   0   0   0]\n",
      " [  3  71   6 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n",
    "\n",
    "#Tokenizing all comments\n",
    "\n",
    "\n",
    "\n",
    "trainX = encode_sequences(tokenizer, com_length, commentaries)\n",
    "print('trainX=\\n', trainX)\n",
    "\n",
    "#Shifting tokenized words by 1 to predict next word in RNN2\n",
    "trainY = np.zeros((len(commentaries), com_length), dtype='int')\n",
    "trainY[:,0:com_length-2] = trainX[:,1:com_length-1]\n",
    "print('\\ntrainY=\\n', trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding RNN2 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y\n",
    "\n",
    "trainY = encode_output(trainY, vocab_size)\n",
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-hot encode inputs in trainX_oh \n",
    "trainX_oh = encode_output(trainX, vocab_size)\n",
    "trainX_oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training data for encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_trainX = []\n",
    "for i, (index, row) in zip(range(len(commentaries)),dfc.iterrows()):\n",
    "    vector = get_pivot_month_Territory_by_brand(row['Month_f'], row['Brand_1'], 0)\n",
    "    var_trainX.append(vector.values.tolist()[0])\n",
    "    if i<5:\n",
    "        print(i, '**', index, '**', row['Month_f'], '**', row['Comment_w'], '**', row['Brand_1'])  \n",
    "        print(trainX[i])\n",
    "        display(vector)  \n",
    "\n",
    "var_trainX = np.asarray(var_trainX)\n",
    "print(var_trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decoder (RNN2)\n",
    "\n",
    "Receives the variance vector that is concatenated with the embedding vector of the word, then is trained to predict the next word using the current word from the commentary of month i related to brand k. \n",
    "\n",
    "**It makes senses also to classify the commentaries in classes, such as: over delivery, driven by territory, orders phased, ...**\n",
    "\n",
    "<img src=\"./images/decoder-arch.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: embed_size = 200\n",
      "Size of LSTM: hidden_size = 256\n",
      "Commentaries vocabulary length: src_vocab = 678\n",
      "Commentaries length (output): src_timesteps = 127\n",
      "Variance vector length: varv_length = 34\n",
      "Number of commentaries: num_comments = 275\n"
     ]
    }
   ],
   "source": [
    "#Embedding size\n",
    "embed_size = 200\n",
    "# Preparing parameters\n",
    "hidden_size = 256\n",
    "# Number of words in vocabulary\n",
    "src_vocab = vocab_size\n",
    "tar_vocab = src_vocab\n",
    "# Max length of input/ouput sentence\n",
    "src_timesteps = com_length #max(len(line.split()) for line in dfc['Comment_w'])\n",
    "tar_timesteps = src_timesteps\n",
    "# Length of variance vector\n",
    "varv_length = len(empty_df.columns)\n",
    "# Number of commentaries\n",
    "num_comments = len(commentaries)\n",
    "\n",
    "#Overview of the parameters calculated from dataset\n",
    "print('Embedding size: embed_size =', embed_size)\n",
    "print('Size of LSTM: hidden_size =', hidden_size)\n",
    "print('Commentaries vocabulary length: src_vocab =', src_vocab)\n",
    "print('Commentaries length (output): src_timesteps =', src_timesteps)\n",
    "print('Variance vector length: varv_length =', varv_length)\n",
    "print('Number of commentaries: num_comments =', num_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder_input_data = (comment_num, variance pos, variance value)  => dimension (comment len, variance vector len, 1)\n",
    "\n",
    "decoder_input_data = (comment num, word pos, word one-hot encoded vector) => (comments number, comment len, )\n",
    "\n",
    "decoder_target_data = (comment num, word pos, word one-hot encoded vector) - words are shifted of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  [(None, 256), (None, 264192      input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  [(None, None, 256),  264192      input_24[0][0]                   \n",
      "                                                                 lstm_15[0][1]                    \n",
      "                                                                 lstm_15[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, None, 679)    174503      lstm_16[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 702,887\n",
      "Trainable params: 702,887\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, 1))   #we feed encoder with one variance by timestep\n",
    "encoder = LSTM(hidden_size, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, 1))  #we feed the decoder with one-hot encoded words\n",
    "#We convert one-hot encoded representation to embedding\n",
    "# comment_Embedding = Embedding(src_vocab, embed_size, input_length=1, mask_zero=True)(decoder_inputs)\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(src_vocab, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')      #rmsprop\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping input/output vectors for LSTM\n",
    "\n",
    "inputs are 3-dim with the following format: (samples, time steps, features)\n",
    "- **Samples**. One sequence is one sample. A batch is comprised of one or more samples.\n",
    "- **Time Steps**. One time step is one point of observation in the sample.\n",
    "- **Features**. One feature is one observation at a time step.\n",
    "\n",
    "\n",
    "\n",
    "**RNN1** :\n",
    "- **samples**: number of comments: `num_comments` \n",
    "- **time steps**: number of territories: `varv_length`\n",
    "- **Features**: one element per territory: `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_trainXr = var_trainX.reshape(num_comments, varv_length, 1)\n",
    "# var_trainXr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN2** :\n",
    "- **samples**: number of comments: `num_comments` \n",
    "- **time steps**: max length of a commentary: `com_length`\n",
    "- **Features**: token of each time step: `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainXr = trainX.reshape(num_comments, com_length, 1)\n",
    "# print(trainXr[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 874 samples, validate on 219 samples\n",
      "Epoch 1/10\n",
      "874/874 [==============================] - 32s 36ms/step - loss: 0.1704 - val_loss: 0.2307\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23075, saving model to unilever.h5\n",
      "Epoch 2/10\n",
      "874/874 [==============================] - 44s 50ms/step - loss: 0.1688 - val_loss: 0.2303\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23075 to 0.23025, saving model to unilever.h5\n",
      "Epoch 3/10\n",
      "874/874 [==============================] - 43s 50ms/step - loss: 0.1677 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23025\n",
      "Epoch 4/10\n",
      "874/874 [==============================] - 37s 42ms/step - loss: 0.1667 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23025\n",
      "Epoch 5/10\n",
      "874/874 [==============================] - 37s 42ms/step - loss: 0.1659 - val_loss: 0.2312\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23025\n",
      "Epoch 6/10\n",
      "874/874 [==============================] - 33s 38ms/step - loss: 0.1649 - val_loss: 0.2307\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23025\n",
      "Epoch 7/10\n",
      "874/874 [==============================] - 36s 41ms/step - loss: 0.1640 - val_loss: 0.2309\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23025\n",
      "Epoch 8/10\n",
      "874/874 [==============================] - 43s 49ms/step - loss: 0.1632 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23025\n",
      "Epoch 9/10\n",
      "874/874 [==============================] - 45s 51ms/step - loss: 0.1623 - val_loss: 0.2312\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23025\n",
      "Epoch 10/10\n",
      "874/874 [==============================] - 38s 43ms/step - loss: 0.1614 - val_loss: 0.2311\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.23025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a7a3b30f0>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 40\n",
    "epochs = 10\n",
    "\n",
    "filename = 'unilever.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit([var_trainXr, trainXr], trainY, batch_size=batch_size, epochs=epochs, validation_split=0.2, \n",
    "          callbacks=[checkpoint], verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling model\n",
    "\n",
    "1) Encode input and retrieve initial decoder state\n",
    "\n",
    "2) Run one step of decoder with this initial state and a \"start of sequence\" token as target. Output will be the next target token.\n",
    "\n",
    "3) Repeat with the current target token and current states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)   #(input,output)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model.predict(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, None, 1)           0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               [(None, 256), (None, 256) 264192    \n",
      "=================================================================\n",
      "Total params: 264,192\n",
      "Trainable params: 264,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  [(None, None, 256),  264192      input_24[0][0]                   \n",
      "                                                                 input_27[0][0]                   \n",
      "                                                                 input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, None, 679)    174503      lstm_16[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 438,695\n",
      "Trainable params: 438,695\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_word_index = dict((i+1, word) for i, word in enumerate(tokenizer.word_index))\n",
    "reverse_input_word_index[0] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c= 2\n",
      "Original comment:  [NOC]\n",
      "target_seq = [[[2.]]]\n",
      "Result =                                                                                                                                \n"
     ]
    }
   ],
   "source": [
    "for c in range(2,3):\n",
    "    print('c=',c)\n",
    "\n",
    "    input_seq = var_trainXr[c:c+1]    #To have 3 dim. One variance vector\n",
    "    print('Original comment: ', commentaries[c])\n",
    "    comment = commentaries[c].split()\n",
    "    # print('input_seq=', input_seq)\n",
    "\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "#     print('states_value =', states_value)\n",
    "\n",
    "    # Generate empty target sequence.\n",
    "    target_seq = np.zeros((1, 1, 1))  \n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, 0] = tokenizer.word_index['[sos]']   \n",
    "#     target_seq = trainXr[c:c+1]\n",
    "    print('target_seq =', target_seq)\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    i = 0\n",
    "    decoded_sentence = []\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "#         print('max probability =',np.max(output_tokens[0, -1, :]))\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "#         print('token of max =', sampled_token_index)\n",
    "        \n",
    "        sampled_word = reverse_input_word_index[sampled_token_index]\n",
    "        decoded_sentence.append (sampled_word)\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_word == '[eos]' or len(decoded_sentence) > src_timesteps):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, 1))\n",
    "        if i<len(comment):\n",
    "            target_seq[0, 0, 0] = tokenizer.word_index[comment[0].lower()]\n",
    "            i = i + 1\n",
    "        else:\n",
    "            target_seq[0, 0, 0] = sampled_token_index\n",
    "#         target_seq[0, 0, 0] = sampled_token_index\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        \n",
    "    print('Result =', ' '.join(decoded_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without encoder +embedding (without variance inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_51 (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_21 (Embedding)     (None, None, 100)         67800     \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, None, 256)         365568    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, None, 678)         174246    \n",
      "=================================================================\n",
      "Total params: 607,614\n",
      "Trainable params: 607,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##################  Second version without variance vector, only training on commentaries with RNN2 #################\n",
    "embed_size = 100\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))    #src_timesteps #we feed the decoder with tokenized word\n",
    "\n",
    "word_Embedding = Embedding(src_vocab, embed_size,  mask_zero=True)  #input_length=src_timesteps,\n",
    "embded_out = word_Embedding(decoder_inputs)\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True)      #, return_sequences=True, return_state=True)\n",
    "decoder_outputs = decoder_lstm(embded_out)  #.reshape(-1,embed_size)     #(decoder_inputs)\n",
    "\n",
    "decoder_dense = Dense(src_vocab, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model(decoder_inputs, decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')      #rmsprop\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 247 samples, validate on 28 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 11s 43ms/step - loss: 1.8229 - val_loss: 5.0899\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 10s 41ms/step - loss: 1.7860 - val_loss: 5.0977\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 10s 41ms/step - loss: 1.7447 - val_loss: 5.0999\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 11s 44ms/step - loss: 1.7053 - val_loss: 5.1284\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 12s 48ms/step - loss: 1.6832 - val_loss: 5.1493\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 10s 42ms/step - loss: 1.6408 - val_loss: 5.1846\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 10s 41ms/step - loss: 1.6036 - val_loss: 5.1784\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 10s 41ms/step - loss: 1.5760 - val_loss: 5.2260\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 10s 41ms/step - loss: 1.5439 - val_loss: 5.1898\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 11s 43ms/step - loss: 1.5245 - val_loss: 5.2257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a1bacd748>"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## Training model without variance #################################\n",
    "batch_size = 20\n",
    "epochs = 10\n",
    "\n",
    "filename = 'unilever_WVOH.h5'\n",
    "# checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(trainX, trainY, batch_size=batch_size, epochs=epochs, validation_split=0.1, \n",
    "           verbose=1)    #callbacks=[checkpoint],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Sampling model without encoder + Embedding #################\n",
    "decoder_outputs = word_Embedding(decoder_inputs)\n",
    "decoder_outputs = decoder_lstm(decoder_outputs)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(decoder_inputs, decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Sampling with model without encoder + Embedding ########\n",
    "\n",
    "for c in range(1,50):\n",
    "    comment = commentaries[c].split()\n",
    "    if comment[1] == '[EOS]': continue\n",
    "\n",
    "    print('\\nc=',c)\n",
    "    print('Original comment: ', commentaries[c])    \n",
    "\n",
    "    # Generate empty target sequence.\n",
    "    target_seq = np.zeros((1, 1))  \n",
    "    # Populate the first character of target sequence with the start character.\n",
    "#     target_seq[0, 0] = tokenizer.word_index['[sos]']       \n",
    "\n",
    "    target_seq[0, 0] = tokenizer.word_index[comment[2].lower()]\n",
    "    print('seed word:', comment[2].lower())\n",
    "\n",
    "#     target_seq = trainXr[c:c+1]\n",
    "#     print('target_seq =', target_seq)\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    i = 0\n",
    "    decoded_sentence = []\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens = decoder_model.predict(target_seq)\n",
    "#         print(output_tokens[0, -1, :])\n",
    "        print('max probability =',np.max(output_tokens[0, -1, :]))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        result = log_probs.data.numpy().tolist()[0]   #Convert tensor to list\n",
    "        result_s = sorted(result, reverse=True)\n",
    "\n",
    "        mydict = [(ix_to_word[result.index(p)], np.exp(p)) for p in result_s[0:topn]]\n",
    "    \n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        print('token of max =', sampled_token_index)\n",
    "        \n",
    "        sampled_word = reverse_input_word_index[sampled_token_index]\n",
    "        decoded_sentence.append (sampled_word)\n",
    "        \n",
    "        break\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_word == '[eos]' or len(decoded_sentence) > src_timesteps):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        if i<len(comment):\n",
    "            target_seq[0, 0] = tokenizer.word_index[comment[0].lower()]\n",
    "            i = i + 1\n",
    "        else:\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "#         target_seq[0, 0, 0] = sampled_token_index\n",
    "\n",
    "        \n",
    "    print('Result =', ' '.join(decoded_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #inputs\n",
    "# variance_input = Input(shape=(varv_length,), name='variance_input')\n",
    "# word_input = Input(shape=(src_timesteps,), name='word_input')\n",
    "\n",
    "# #Defining embedding layer: keras.layers.Embedding(input_dim, output_dim)\n",
    "# comment_Embedding = Embedding(src_vocab, embed_size, input_length=src_timesteps, mask_zero=True)(word_input)\n",
    "\n",
    "# #merge word embeddings and variance vector\n",
    "# # merged = concatenate([variance_rep, comment_Embedding])\n",
    "\n",
    "# #Creating dense layer for LSM initialization by variance input\n",
    "# dense_var = Dense(hidden_size, activation='relu')(variance_input)\n",
    "\n",
    "# #Defining LSTM\n",
    "# # decoder = LSTM(units=hidden_size, return_sequences=True, initial_state=dense_var)(comment_Embedding)\n",
    "\n",
    "# decoder_lstm = LSTM(hidden_size)\n",
    "# decoder_outputs = decoder_lstm(comment_Embedding)   #, initial_state=dense_var\n",
    "\n",
    "# decoder_dense = Dense(src_vocab, activation='softmax')(decoder_outputs)\n",
    "\n",
    "# model = Model(inputs=[word_input], outputs=[decoder_dense])\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #variance inputs\n",
    "# variance_input = Input(shape=(None, varv_length), name='variance_input')\n",
    "# word_input = Input(shape=(None, src_vocab), name='word_input')\n",
    "\n",
    "# #Defining embedding layer: keras.layers.Embedding(input_dim, output_dim)\n",
    "# comment_Embedding = Embedding(src_vocab, embed_size, input_length=src_timesteps, mask_zero=True)(word_input)\n",
    "\n",
    "# #merge word embeddings and variance vector\n",
    "# merged = Concatenate([variance_inputs, comment_Embedding])\n",
    "\n",
    "# decoder = LSTM(units=hidden_size, input_shape=(varv_length + embed_size,), return_sequences=True)\n",
    "\n",
    "# # encoder_outputs, state_h, state_c = decoder(merged)\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(merged)\n",
    "# model.add(decoder)\n",
    "# model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define NMT model\n",
    "# def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "#     model = Sequential()\n",
    "#     #Defining embedding layer: keras.layers.Embedding(input_dim, output_dim)\n",
    "#     model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "#     # Defining Encoder LSTM\n",
    "#     model.add(LSTM(n_units))    \n",
    "#     #Defining Decoder LSTM    \n",
    "#     model.add(RepeatVector(tar_timesteps))\n",
    "#     model.add(LSTM(n_units, return_sequences=True))   \n",
    "#     model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "#     return model\n",
    "\n",
    "# model = define_model(fre_vocab_size, eng_vocab_size, fre_length, eng_length, 256)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     first = Sequential()\n",
    "#     first.add(Dense(1, input_doi=(2,), activation='sigmoid'))\n",
    "\n",
    "#     second = Sequential()\n",
    "#     second.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n",
    "\n",
    "#     third = Sequential()\n",
    "#     # of course you must provide the input to result with will be your x3\n",
    "#     third.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "#     merged = Concatenate([first, second])\n",
    "    \n",
    "\n",
    "\n",
    "# def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, hidden_size):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(vocabulary, hidden_size, input_length=num_steps))\n",
    "#     model.add(LSTM(hidden_size, return_sequences=True))\n",
    "#     model.add(LSTM(hidden_size, return_sequences=True))\n",
    "#     if use_dropout:\n",
    "#         model.add(Dropout(0.5))\n",
    "#     model.add(TimeDistributed(Dense(vocabulary)))\n",
    "#     model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define model\n",
    "# model = define_model(fre_vocab_size, eng_vocab_size, fre_length, eng_length, 256)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# # summarize defined model\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old pytorch code\n",
    "#----------------\n",
    "\n",
    "\n",
    "# class DecoderRNN(nn.Module):\n",
    "#     def __init__(self, hidden_size, output_size):\n",
    "#         super(DecoderRNN, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#         self.embedding = nn.Embedding(output_size, hidden_size)  #input and input sizes are identical\n",
    "#         self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "#         self.out = nn.Linear(hidden_size, output_size)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input, hidden):\n",
    "#         output = self.embedding(input).view(1, 1, -1)\n",
    "#         output = F.relu(output)\n",
    "#         output, hidden = self.gru(output, hidden)\n",
    "#         output = self.softmax(self.out(output[0]))\n",
    "#         return output, hidden\n",
    "\n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embedding): Embedding(1, 300)\n",
      "  (gru): GRU(300, 300)\n",
      "  (out): Linear(in_features=300, out_features=1, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder = DecoderRNN(300, 1)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define components sizes\n",
    "CONTEXT_SIZE_1 = 300\n",
    "CONTEXT_SIZE_2 = 300\n",
    "EMBEDDING_DIM = 30\n",
    "\n",
    "\n",
    "encoder = EncoderRNN(VAR_MONTH_DATA_SIZE, CONTEXT_SIZE_1)\n",
    "decoder = DecoderRNN(CONTEXT_SIZE_2, 1)\n",
    "\n",
    "learning_rate=0.01\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteration here\n",
    "encoder_hidden = encoder.initHidden()\n",
    "encoder_optimizer.zero_grad()\n",
    "decoder_optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training, you can re-run this function as much time as needed to train more\n",
    "for epoch in range(60):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    print('epoch %d : Total loss=%.3f' % (epoch, total_loss))\n",
    "#print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) #Embedding matrix: each line is the embedding of one word\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128) #Parameter matrix embedding and hidden layer\n",
    "        self.linear2 = nn.Linear(128, vocab_size)  #Parameter matrix between hidden layer and output\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))  #get embedding from Embedding matrix\n",
    "        out = F.relu(self.linear1(embeds))  #\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)   #before 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training, you can re-run this function as much time as needed to train more\n",
    "for epoch in range(60):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    print('epoch %d : Total loss=%.3f' % (epoch, total_loss))\n",
    "#print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "          max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting results\n",
    "----------------\n",
    "\n",
    "Plotting is done with matplotlib, using the array of loss values\n",
    "``plot_losses`` saved while training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a paragraph with in between and then there are cases ... where the number ranges from 1-100. and there are many other lines in the txt files with such tags '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line='this is a paragraph with<[1> in between</[1> and then there are cases ... where the<[99> number ranges from 1-100</[99>. and there are many other lines in the txt files with<[3> such tags </[3>'\n",
    "import re\n",
    "line = re.sub(r\"</?\\[\\d+>\", \"\", line)\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "comment = 'baselines driven by improving pos l4 +3%'\n",
    "aa = r\"[0-9]+(\\.[0-9]+)?\\%\"\n",
    "comment = re.sub(aa, \"[%]\", comment)\n",
    "comment = re.sub(r\"\\-\\$[0-9].[0-9][0-9]M\\b\", \"[-]\", comment)\n",
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/(^|\\W)$[0-9]+(\\.[0-9][0-9])?\\b/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated version of Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, None, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 200), (None, 176800      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 200),  184800      input_6[0][0]                    \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 30)     6030        lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 367,630\n",
      "Trainable params: 367,630\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "num_encoder_tokens = 20\n",
    "latent_dim = 200\n",
    "encoder_inputs = 1\n",
    "\n",
    "num_decoder_tokens = 30\n",
    "decoder_outputs = 150\n",
    "\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 200), (None, 240800      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 200),  200800      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 50)     10050       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 451,650\n",
      "Trainable params: 451,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
